{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Methods in Astronomy: Hands-on Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Picture: What Are We After?\n",
    "\n",
    "There are two fundamental types of statistical questions we'll want to answer:\n",
    "\n",
    "#### 1. Model Fitting\n",
    "*Given this Model, what parameters best fit my data?*\n",
    "\n",
    "Examples:\n",
    "\n",
    "- What are the slope and intercept of a line of best-fit?\n",
    "- What are the parameters of the best quadratic fit?\n",
    "- What is the frequency, amplitude, and phase of a sinusoidal fit?\n",
    "- What are the orbital parameters of a planet in this radial velocity data?\n",
    "\n",
    "#### 2. Model Selection\n",
    "\n",
    "*Given two potential Models, which better describes my data?*\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Is there a linear trend in this data?\n",
    "- Does a linear or quadratic fit describe our data better?\n",
    "- Is there a periodic signal in this timeseries?\n",
    "- Does this star have a planet around it? Does this star have two planets around it?\n",
    "\n",
    "Often one of the two models is a *null hypothesis*, or a baseline model in which the effect you're interested in is not observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequentist vs Bayesian Approaches\n",
    "\n",
    "Both the model fitting and model selection problems can be approached from either a *frequentist* or a *Bayesian* standpoint.\n",
    "Fundamentally, the difference between these lies in the **definition of probability** that they use:\n",
    "\n",
    "- **A frequentist probability is a measure *long-run frequency* of (real or imagined) repeated trials.** Among other things, this generally means that observed data can be described probabilistically (you can repeat the experiment and get a different realization) while model parameters are fixed, and cannot be described probabilistically (the universe remains the same no matter how many times you observe it).\n",
    "\n",
    "- **A Bayesian probability is a *quantification of belief*.** Among other things, this generally means that observed data are treated as fixed (you know exactly what values you measured) while model parameters – including the \"true\" values of the data reflected by noisy measurements – are treated probabilistically (your degree of knowledge about the universe changes as you gather more data).\n",
    "\n",
    "Perhaps surprisingly to the uninitiated, people have been vehemently fighting in favor of one approach or the other for decades.\n",
    "For more a more fleshed-out discussion of these different definitions and their consequences, you can see my [series of blog posts](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/) on the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bayesian Problem Setting\n",
    "\n",
    "Thus the end-goal of a Bayesian analysis is a probabilistic statement about the universe.\n",
    "Roughly we want to measure\n",
    "\n",
    "$$\n",
    "P(science)\n",
    "$$\n",
    "\n",
    "Where \"science\" might be encapsulated in the cosmological model, the mass of a planet around a star, or whatever else we're interested in learning about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't of course measure this without reference to data, so more specifically we want to measure\n",
    "\n",
    "$$\n",
    "P(science~|~data)\n",
    "$$\n",
    "\n",
    "which should be read \"the probability of the science *given* the data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we should be explicit that this measurement is not done in a vaccum: generally before observing any data we have *some* degree of background information that informs the science, so we should actually write\n",
    "\n",
    "$$\n",
    "P(science~|~data, background\\ info)\n",
    "$$\n",
    "\n",
    "This should be read \"the probability of the science given the data *and* the background information\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there are often things in the scientific model that we don't particularly care about: these are known as \"nuisance parameters\". As an example of a nuisance parameter, if you are finding a planet in radial velocity data, the secular motion of the star is *extremely* important to model correctly, but in the end you don't really care about its best-fit value.\n",
    "\n",
    "With that in mind, we can write:\n",
    "\n",
    "$$\n",
    "P(science,nuisance\\ parameters~|~data, background\\ info)\n",
    "$$\n",
    "\n",
    "Where as before the comma should be read as an \"and\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is starting to get a bit cumbersome, so let's create some symbols that will let us express this more easily:\n",
    "\n",
    "$$\n",
    "P(\\theta_S, \\theta_N~|~D, I)\n",
    "$$\n",
    "\n",
    "- $\\theta_S$ represents the \"science\": the vector of parameters that we are interested in constraining\n",
    "- $\\theta_N$ represents the \"nuisance parameters\": the vector of parameters that are important in the model, but are not particularly interesting for the scientific result.\n",
    "- $D$ represents the \"observed data\"\n",
    "- $I$ represents the information or knowledge you had before observing the data, including whatever made you choose the model you're fitting.\n",
    "\n",
    "Finally, we'll often just write $\\theta = (\\theta_S, \\theta_N)$ as a shorthand for all the model parameters.\n",
    "\n",
    "This quantity, $P(\\theta~|~D,I)$ is called the \"posterior probability\" and determining this quantity is the ultimate goal of a Bayesian analysis.\n",
    "\n",
    "Now all we need to do is compute it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Nitty Gritty: Thinking about Probability\n",
    "\n",
    "### Normalization of Probability\n",
    "\n",
    "That is, we can write\n",
    "$$\n",
    "\\int P(A) dA = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional probability\n",
    "\n",
    "We can write\n",
    "$$\n",
    "P(A\\mid B) = \\frac{P(A, B)}{P(B)}\n",
    "$$\n",
    "Rearranging this we get the more common expression of this:\n",
    "$$\n",
    "P(A, B) = P(A\\mid B)P(B)\n",
    "$$\n",
    "\n",
    "Note that conditional probabilities are still probabilities, so that the normalization is the same as above:\n",
    "$$\n",
    "\\int P(A\\mid B)dA = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginalization\n",
    "\n",
    "Given the above two properties, we can quite easily show that\n",
    "$$\n",
    "\\int P(A, B) dA = P(B)\n",
    "$$\n",
    "This is known as *marginalization* – we have integrated *A* out of the joint probability, and we are left with the raw probability of *B*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' Rule\n",
    "\n",
    "The definition of conditional probability is entirely symmetric, so we can write\n",
    "\n",
    "$$\n",
    "P(A, B) = P(B, A)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(A\\mid B)P(B) = P(B\\mid A)P(A)\n",
    "$$\n",
    "\n",
    "which is more commonly rearranged in this form:\n",
    "\n",
    "$$\n",
    "P(A\\mid B) = \\frac{P(B\\mid A)P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "This is known as *Bayes' Theorem* or *Bayes' Rule*, and is important because it gives a formula for \"flipping\" conditional probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Bayes' Rule to Bayesian Inference\n",
    "\n",
    "If we replace these labels, we find the usual expression of Bayes' theorem as it relates to model fitting:\n",
    "\n",
    "$$\n",
    "P(\\theta \\mid D) = \\frac{P(D\\mid\\theta)P(\\theta)}{P(D)}\n",
    "$$\n",
    "\n",
    "Technically all the probabilities should all be conditioned on the information $I$:\n",
    "\n",
    "$$\n",
    "P(\\theta \\mid D,I) = \\frac{P(D \\mid \\theta,I)P(\\theta \\mid I)}{P(D \\mid I)}\n",
    "$$\n",
    "\n",
    "In terms of Bayesian analysis, each of these terms have a precise name and meaning:\n",
    "\n",
    "- $P(\\theta\\mid D, I)$ is the *posterior*. This is the quantity we want to compute: our knowledge of the model given the data & background knowledge (including the choice of model).\n",
    "- $P(D\\mid\\theta,I)$ is the *likelihood*. This measures the probability of seeing our data given the model. This is identical to the expression that is maximized in frequentist *maximum-likelihood* approaches.\n",
    "- $P(\\theta\\mid I)$ is the *prior*. This encodes any knowledge we had about the answer before measuring the current data.\n",
    "- $P(D\\mid I)$ is the *Fully Marginalized Likelihood*, or *FML* (also called the *Evidence* among other things). In the context of model fitting, it acts as a normalization constant and in most cases can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside on the FML\n",
    "\n",
    "In general the Fully Marginalized Likelihood (FML) is **very costly** to compute, which makes the acronym doubly appropriate in any situation where you actually need it.\n",
    "To see why it's so costly, consider that the FML can be expressed as an integral using the identities we covered above:\n",
    "$$\n",
    "P(D\\mid I) = \\int P(D\\mid\\theta, I) P(\\theta) d\\theta\n",
    "$$\n",
    "In other words, it is the integral over the likelihood for *all possible values of theta*.\n",
    "When your likelihood is a complicated function of many parameters, computing this integral can become extremely costly (a manifestation of the *curse of dimensionality*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginalizing the nuisance parameters\n",
    "\n",
    "We now have a recipe for computing the posterior, $P(\\theta\\mid D,I)$. Recall that in general our model parameters $\\theta$ contain some parameters of interest (what we called $\\theta_S$, or the \"science\") and some nuisance parameters (what we called $\\theta_N$).\n",
    "\n",
    "What we're really interested in, then, is $P(\\theta_S\\mid D, I)$ which we can compute via a straightforward integral:\n",
    "\n",
    "$$\n",
    "P(\\theta_S\\mid D, I) = \\int P(\\theta_S, \\theta_N\\mid D, I)d\\theta_N\n",
    "$$\n",
    "\n",
    "where the integral is over the entire space of $\\theta_N$.\n",
    "This quantity, the marginalized posterior, is our final result of interest.\n",
    "\n",
    "At first glance, you might think this problem would be just as difficult as the computation of the FML above.\n",
    "We'll see later, however, that a feature of the MCMC approaches typical for large Bayesian problems is that such marginalized likelihoods come essentially for free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking forward\n",
    "\n",
    "We now have all the probabilistic machinery we need to do Bayesian inference... next we will get our fingers on our keyboards and fit some Bayesian models!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
